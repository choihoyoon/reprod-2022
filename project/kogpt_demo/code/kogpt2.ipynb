{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "7a3f59cb-3ff1-4d06-8170-1c6fd8413463",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "nE_eXv_s1e1b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFGPT2Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "c8f20fb5-3183-4aa8-b561-27fc7bd9baef",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "ow6Rfi472RNA"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    input_ids, data_labels = [], []\n",
    "    \n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        bos_token = [tokenizer.bos_token]\n",
    "        eos_token = [tokenizer.eos_token]\n",
    "        tokens = bos_token + tokenizer.tokenize(example) + eos_token\n",
    "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        input_ids.append(input_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "    \n",
    "    return input_ids, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "7e65ae29-f895-4a8b-bac0-e4e602b06554",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "AxdWu-fp2TX5"
   },
   "outputs": [],
   "source": [
    "class TFGPT2ForSequenceClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name, activation, num_labels):\n",
    "        super(TFGPT2ForSequenceClassification, self).__init__()\n",
    "        self.gpt = TFGPT2Model.from_pretrained(model_name, from_pt=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.19592891961278336)\n",
    "        self.classifier = tf.keras.layers.Dense(num_labels,\n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "                                                activation=activation,\n",
    "                                                name='classifier')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        outputs = self.gpt(input_ids=inputs)\n",
    "        cls_token = outputs[0][:, -1]\n",
    "        cls_token = self.dropout(cls_token)\n",
    "        prediction = self.classifier(cls_token)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "8702ead1-bb2f-4dbe-814e-fb6a0858c095",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "ipPOZgtV2VRP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "d43d8b22-7f39-426b-ac50-0717c167935f",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "HAZ3oJk42X__"
   },
   "outputs": [],
   "source": [
    "target = df[['RCMN_CD1']]\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=777, shuffle=True,\n",
    "                                         stratify=target)\n",
    "target = train_data[['RCMN_CD1']]\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.2, random_state=777, shuffle=True,\n",
    "                                          stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "50dbf593-7002-4cd3-bbef-c1485971dc74",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "SeBrZ2mh2dU7"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2',\n",
    "                                          bos_token='</s>', eos_token='</s>', pad_token='<pad>')\n",
    "max_seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "e517520b-37f9-4ca5-a650-cb287eade5bf",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "h2pDXZag2fSD"
   },
   "outputs": [],
   "source": [
    "train_X, train_y = convert_examples_to_features(train_data['PAPER_TEXT'], train_data['RCMN_CD1'],\n",
    "                                                max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "valid_X, valid_y = convert_examples_to_features(valid_data['PAPER_TEXT'], valid_data['RCMN_CD1'],\n",
    "                                                max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "test_X, test_y = convert_examples_to_features(test_data['PAPER_TEXT'], test_data['RCMN_CD1'],\n",
    "                                              max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "eacdbbbd-c177-4a6f-ab4a-44d0a7b9b9ff",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "z1HKJneA2mLZ"
   },
   "outputs": [],
   "source": [
    "if 'multi-class' == 'binary':\n",
    "    model = TFGPT2ForSequenceClassification(\"skt/kogpt2-base-v2\", activation='sigmoid', num_labels=1)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "elif 'multi-class' == 'multi-class':\n",
    "    num_labels = df['RCMN_CD1'].nunique()\n",
    "    model = TFGPT2ForSequenceClassification(\"skt/kogpt2-base-v2\", activation='softmax', num_labels=num_labels)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "46813f0b-2b63-49fd-a723-080e79bdc3a4",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "PNfdQfUi2yyk"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1.6266246859806895e-05)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f66de041-e1e1-4e4c-9604-026b8fea7353",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "290JUCAX20Nj"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_y, epochs=4, batch_size= 8,\n",
    "                    validation_data=(valid_X, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "ea8c3831-ca4a-4ae3-af7f-e36794bbe654",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "_h-erMNo22_I"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_X, test_y)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": []
  },
  "colab": {
   "authorship_tag": "ABX9TyMZnNcj3bDKWJ9I9GZBrudP",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (Link)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}